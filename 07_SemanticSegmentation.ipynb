{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Semantic Segmentation\n",
    "Heute werden wir einfache Netzwerkarchitekturen für \"Semantic Segmentation\" testen. Ziel ist es dieses Paper in den Grundzügen zu implementieren: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf. Bitte lesen!\n",
    "\n",
    "## Daten\n",
    "\n",
    "Es gibt einige gute Datensätze, die ihr (bei gegebener Hardware) herunterladen und benutzen könnt. Für diejenigen, die auf CPUs rechnen gilt immer der Tip: Bilder downsamplen!\n",
    "\n",
    "Sucht Euch einen Satensatz aus: \n",
    "\n",
    "KITTI: http://www.cvlibs.net/download.php?file=data_semantics.zip (~300 MB, 200 Bilder)\n",
    "\n",
    "DUS: http://www.6d-vision.com/scene-labeling (~3 GB, 500 Bilder)\n",
    "\n",
    "MIT. http://sceneparsing.csail.mit.edu/ (~1 GB, links siehe auf Seite)\n",
    "\n",
    "## Exc. 7.1 Fully convolutional network, no downsampling\n",
    "Implementiere die in der Vorlesung besprochene Netzwerkarchitektur von aufeinanderfolgenden CONV-Schichten (stride=1, mit zero-padding), um eine Ausgabeschicht zu bekommen, die die Eingabegröße aufweist. Tip: die letzte CONV-Schicht sollte eine Tiefe haben, die zur Zahl der Klassen korrespondiert. Benutze den L2-Loss zum Labelbild (Achtung: ihr müsst dafür entweder das Labelbild oder den Ausgabetensor umformulieren).\n",
    "\n",
    "Trainiere das Netzwerk auf den von Dir gewählten Datensatz und zeige den Verlauf des Losses, und einige zufällig gewählte Beispielbilder mit ihren vorhergesagten Segmentierungen an. (**RESULT**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 1 classes.\n",
      "Found 180 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_generator = ImageDataGenerator()\n",
    "label_generator = ImageDataGenerator()\n",
    "\n",
    "# Beispiel für den KITTI-Datensatz. Ich habe die 200 training samples in 180 train- und 20 testbilder\n",
    "# geteilt (macht 180 samples inkl. labels)\n",
    "# um uns das Leben leichter zu machen, Bilder heruntersamplen\n",
    "img_size = (38, 125)\n",
    "\n",
    "\n",
    "# Bild- und Label-Generator\n",
    "Q1 = image_generator.flow_from_directory( 'C:/Users/Tim/Downloads/seg_data/train/images',\n",
    "                                        class_mode = None,\n",
    "                                        batch_size=1,\n",
    "                                        target_size=img_size, seed=1)\n",
    "\n",
    "Q2 = label_generator.flow_from_directory( 'C:/Users/Tim/Downloads/seg_data/train/labels',\n",
    "                                       \n",
    "                                         class_mode = None,\n",
    "                                        batch_size=1,\n",
    "                                        target_size=img_size, seed=1)\n",
    "\n",
    "# ... kombinieren\n",
    "train_generator = zip(Q1, Q2)\n",
    "\n",
    "# mach der Definition des Modells:\n",
    "# model.fit_generator( train_generator, steps_per_epoch = 1000, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exc. 7.2 FCN mit Bottleneck\n",
    "\n",
    "Implementiere jetzt die Variante mit schrittweisem Down- und Upsampling, wie in der Vorlesung besprochen. Nutze dafür ein bestehendes Netzwerk (z.B. VGG16, https://keras.io/applications/#vgg16), entferne die FC-Schichten am Ende, und füge dann die Upsampling-Schichten hinzu. Wie in der vorigen Vorlesung zu Transfer Learning beschrieben, kannst Du jetzt nur den zweiten Teil trainieren und die Gewichte des ersten Teils \"einfrieren\".\n",
    "\n",
    "Stelle wie oben den Verlauf des Losses dar und wähle einige Beispielbilder aus dem Testset und zeige sie mit ihrer vorhergesagten Segmentierung an. (**BONUS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
